---
title: "Metalearning in Time Series Ensembles"
subtitle: "Using Deep Learning to Select Statistical Models"
date: "2023-09-01"
author: "Corwin Dark"
image: "image.jpg"
---



Get Hourly SPY Data Since 1/1/22
```{python}
import yfinance as yf
import pandas as pd
from datetime import datetime
data = yf.download('SPY','2022-01-01','2023-09-30', interval ="60m")
import matplotlib.pyplot as plt
%matplotlib inline

data['Adj Close'].plot()
plt.ion()

```


Now we need to split the data.

``` {python}
data.reset_index(inplace=True)
print(data)


# maybe consider splitting by whole days here
# 20% test split
train_size = 2400

data_train = data[:train_size]
data_test = data[train_size:]

test_size = len(data_test)
# 656 today

data_test = data_test[["Datetime", "Close"]]
data_train = data_train[["Datetime", "Close"]]

seriesTrain = data_train.set_index('Datetime')
seriesTest = data_test.set_index('Datetime')

'''
clean_test = data_test

clean_test['unique_id'] = range(0, len(clean_test['Close']))

clean_test.rename({"Datetime" : "ds", "Close": "y"}, axis = "columns", inplace = True)
clean_test = pd.DataFrame(clean_test)

clean_test = clean_test[['unique_id', 'ds', 'y']]
'''





```


``` {python}

def crossValidation(train, test, window, predReturnFunction):
    totalPredictions = []
    windows = len(test) // window

    for i in range(0, windows):
        print("Window: ", i)

        addNum = i * window
        intermediateData = train.append(test[:addNum])
        prediction = predReturnFunction(intermediateData, window)
        print(prediction)

        for i in range(1, len(prediction)):
            totalPredictions = totalPredictions + [prediction[i]]
    
    #remove hanging dates if somem were not included in a window
    # to make test indices the same length as the predictions
    #testSheared = test[:(windows*window)]
    #totalPredictions.index = testSheared.index

    return totalPredictions



```

And then we need to train the statistical models


```{python}


from pmdarima.arima import auto_arima
from pmdarima import model_selection

def aaPredFunction(dataIn, windowSize):
    model = auto_arima(dataIn)
    predictions = model.predict(n_periods = windowSize)
    return predictions

#aaModel = auto_arima(seriesTrain)
test_out_size = 5


tempTest = seriesTest[:test_out_size]
print(model_selection.cross_val_predict(, tempTest))

tempModel = auto_arima(seriesTrain)

tempModel.summary()
cv = model_selection.RollingForecast(window_size=1, step=1, h=1)
model1_cv_scores = model_selection.cross_val_score(
    tempModel, seriesTest, scoring='smape', cv=cv, verbose=2)

model1_cv_scores
#aaPrediction = crossValidation(seriesTrain, tempTest, 1, aaPredFunction)
```

```{python}

backN = 50

smallTest = seriesTest[:test_out_size]
smallTrain = seriesTrain[-backN:]

smallTest["x"] = range(backN + 1,backN + test_out_size + 1)
smallTrain["x"] = range(1,backN + 1)

#aaPrediction = pd.Series(aaPrediction)
#aaPrediction.index = smallTest.index
aaPrediction2 = pd.DataFrame([float(x) for x in aaPrediction])
aaPrediction2["x"] = range(backN + 1, backN + test_out_size + 1)
aaPrediction2.rename(columns = {0 : "val", "x": "x"}, inplace = True )
aaPrediction2 = pd.DataFrame(aaPrediction2)

print(aaPrediction)
#print(smallTest["Close"])

plt.figure(figsize= (8,5) )
plt.plot(smallTrain["x"], smallTrain["Close"], label = "Training")
plt.plot(smallTest["x"], smallTest["Close"], label = "Test")
plt.plot(aaPrediction2["x"], aaPrediction2["val"], label = "Auto Arima")
plt.legend(loc = 'upper left')
plt.show()
```



And then we can reformat data for NN









