{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Metalearning in Time Series Ensembles\"\n",
        "subtitle: \"Using Deep Learning to Select Statistical Models\"\n",
        "date: \"2023-09-01\"\n",
        "author: \"Corwin Dark\"\n",
        "image: \"image.jpg\"\n",
        "---"
      ],
      "id": "2195253c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get Hourly SPY Data Since 1/1/22"
      ],
      "id": "b2122078"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as plt\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "from datetime import datetime\n",
        "data = yf.download('SPY','2022-01-01','2023-09-30', interval =\"60m\")\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "data['Adj Close'].plot()\n",
        "plt.ion()\n",
        "print(data)"
      ],
      "id": "59cb068e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we need to split the data.\n"
      ],
      "id": "c9035386"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#data.reset_index(inplace=True)\n",
        "\n",
        "\n",
        "# maybe consider splitting by whole days here\n",
        "# 20% test split but could do more\n",
        "# or 30% or 50%\n",
        "train_size = 2400\n",
        "\n",
        "data_train = data[:train_size]\n",
        "data_test = data[train_size:]\n",
        "\n",
        "test_size = len(data_test)\n",
        "# 656 as of today\n",
        "\n",
        "data_test = data_test[[\"Datetime\", \"Close\"]]\n",
        "data_train = data_train[[\"Datetime\", \"Close\"]]\n",
        "\n",
        "seriesTrain = data_train.set_index('Datetime')\n",
        "seriesTest = data_test.set_index('Datetime')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "clean_test = data_test\n",
        "\n",
        "clean_test['unique_id'] = range(0, len(clean_test['Close']))\n",
        "\n",
        "clean_test.rename({\"Datetime\" : \"ds\", \"Close\": \"y\"}, axis = \"columns\", inplace = True)\n",
        "clean_test = pd.DataFrame(clean_test)\n",
        "\n",
        "clean_test = clean_test[['unique_id', 'ds', 'y']]\n",
        "'''"
      ],
      "id": "812e528e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Attempting to implement with sklearn tscv "
      ],
      "id": "c2a16183"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tscvData = data[[\"Close\"]]\n",
        "\n",
        "\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html\n",
        "\n",
        "tscv = TimeSeriesSplit(gap=0 max_train_size=None, n_splits=5, test_size=1)\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(tscv.split(tscvData)):\n",
        "    print(i, \"train: \", train_index, \"test: \", test_index)\n",
        "    model = auto_arima(tscvData[train_index])\n",
        "    predictions = model.predict(n_periods = 1)\n",
        "    print(predictions)"
      ],
      "id": "cf8682ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def crossValidation(train, test, window, predReturnFunction):\n",
        "\n",
        "    totalPredictions = pd.Series([])\n",
        "    windows = len(test) // window\n",
        "\n",
        "    for i in range(0, windows):\n",
        "        print(\"Window: \", i)\n",
        "\n",
        "        addNum = i * window\n",
        "        intermediateData = train.append(test[:addNum])\n",
        "        #print(test[:addNum])\n",
        "        prediction = predReturnFunction(intermediateData, window)\n",
        "        \n",
        "        print(prediction)\n",
        "        #print(prediction.shape)\n",
        "\n",
        "        #for i in range(1, len(prediction)):\n",
        "        #    totalPredictions = totalPredictions.append#(prediction)\n",
        "        Series.append(totalPredictions, prediction, verify_integrity = True)\n",
        "        print(totalPredictions)\n",
        "\n",
        "\n",
        "    #remove hanging dates if somem were not included in a window\n",
        "    # to make test indices the same length as the predictions\n",
        "    #testSheared = test[:(windows*window)]\n",
        "    #totalPredictions.index = testSheared.index\n",
        "\n",
        "    return totalPredictions\n"
      ],
      "id": "c0742c75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And then we need to train the statistical models\n",
        "\n",
        "\n",
        "Import packages"
      ],
      "id": "1ca64fb4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pmdarima.arima import auto_arima\n",
        "from pmdarima import model_selection"
      ],
      "id": "d0551c96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run Prediction"
      ],
      "id": "8551372c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def aaPredFunction(dataIn, windowSize):\n",
        "    model = auto_arima(dataIn, seasonal = False, stepwise = False)\n",
        "    predictions = model.predict(n_periods = windowSize)\n",
        "    return predictions\n",
        "\n",
        "#aaModel = auto_arima(seriesTrain)\n",
        "test_out_size = 3\n",
        "\n",
        "\n",
        "tempTest = seriesTest[:test_out_size]\n",
        "#print(model_selection.cross_val_predict(, tempTest))\n",
        "\n",
        "tempModel = auto_arima(seriesTrain)\n",
        "\n",
        "tempModel.summary()\n",
        "#cv = model_selection.RollingForecast(window_size=1, step=1, h=1)\n",
        "#model1_cv_scores = model_selection.cross_val_score(\n",
        "#   tempModel, seriesTest, scoring='smape', cv=cv, verbose=2)\n",
        "\n",
        "#model1_cv_scores\n",
        "aaPrediction = crossValidation(seriesTrain, tempTest, 1, aaPredFunction)"
      ],
      "id": "7345f092",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try and visualize the cross-validated auto-arima performance\n"
      ],
      "id": "aa72374b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#print(aaPrediction[0].tostring)\n",
        "#aaPrediction = pd.DataFrame(aaPrediction)\n",
        "aaPrediction[1].plot()\n",
        "\n",
        "#sns.lineplot(aaPrediction, x = aaPrediction.index, y = aaPrediction)"
      ],
      "id": "0e0c786a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "backN = 50\n",
        "\n",
        "smallTest = seriesTest[:test_out_size]\n",
        "smallTrain = seriesTrain[-backN:]\n",
        "\n",
        "smallTest[\"x\"] = range(backN + 1,backN + test_out_size + 1)\n",
        "smallTrain[\"x\"] = range(1,backN + 1)\n",
        "\n",
        "#aaPrediction = pd.Series(aaPrediction)\n",
        "#aaPrediction.index = smallTest.index\n",
        "#aaPrediction = pd.Series(aaPrediction)\n",
        "#aaPrediction.index = smallTest.index\n",
        "aaPrediction2 = pd.DataFrame([float(x) for x in aaPrediction])\n",
        "aaPrediction2[\"x\"] = range(backN + 1, backN + test_out_size + 1)\n",
        "aaPrediction2.rename(columns = {0 : \"val\", \"x\": \"x\"}, inplace = True )\n",
        "aaPrediction2 = pd.DataFrame(aaPrediction2)\n",
        "\n",
        "print(aaPrediction)\n",
        "\n",
        "plt.figure(figsize= (8,5) )\n",
        "plt.plot(smallTrain[\"x\"], smallTrain[\"Close\"], label = \"Training\")\n",
        "plt.plot(smallTest[\"x\"], smallTest[\"Close\"], label = \"Test\")\n",
        "plt.plot(aaPrediction2[\"x\"], aaPrediction2[\"val\"], label = \"Auto Arima\")\n",
        "plt.legend(loc = 'upper left')\n",
        "plt.show()"
      ],
      "id": "77cca4bb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And then we can reformat data for NN\n"
      ],
      "id": "7f985411"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}